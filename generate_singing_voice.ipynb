{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pyrubberband as pyrb\n",
    "import boto3\n",
    "import os\n",
    "import wave\n",
    "from scipy import signal\n",
    "from io import BytesIO\n",
    "\n",
    "polly_client = boto3.client('polly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingingVoiceGenerator():\n",
    "    def __init__(\n",
    "        self, \n",
    "        scale = 'A',\n",
    "        length_sec = 1,\n",
    "        text = 'あ', \n",
    "        engine = 'standard', \n",
    "        language = 'ja-JP',\n",
    "        output_format = 'pcm',\n",
    "        sample_rate = 16000,\n",
    "        text_type = 'text',\n",
    "        voice_id = 'Mizuki',\n",
    "        sep_num = 3\n",
    "    ):\n",
    "        self.scale = scale\n",
    "        self.length_sec = length_sec\n",
    "        self.text = text\n",
    "        self.engine = engine\n",
    "        self.language = language\n",
    "        self.output_format = output_format\n",
    "        self.sample_rate = sample_rate\n",
    "        self.text_type = text_type\n",
    "        self.voice_id = voice_id\n",
    "        self.sep_num = 4\n",
    "        self._scale_list = ['L-A','L-As','L-H','C','Cs','D','Ds','E','F','Fs','G','Gs','A','As','H','H-C','H-Cs','H-D','H-Ds','H-E','H-F','H-Fs','H-G','H-Gs','H-A']\n",
    "        self._scale_dict = {}\n",
    "        for i, key in enumerate(self._scale_list):\n",
    "            freq = 442 * (2 ** ((-12+i)/12))\n",
    "            self._scale_dict[key] = freq\n",
    "        self.scale_freq = self._scale_dict[self.scale]\n",
    "        self.raw_pcm_bin = self.generate_voice_data()\n",
    "        self.shift_pcm_array = self.pitch_shift()\n",
    "        self.time_stretch_array = self.time_stretch()\n",
    "    def generate_voice_data(self):\n",
    "        raw_pcm_bin = BytesIO()\n",
    "        raw_pcm_bin.name = 'raw.wav'\n",
    "        args = {\n",
    "            'Engine':self.engine,\n",
    "            'LanguageCode':self.language,\n",
    "            'OutputFormat':self.output_format,\n",
    "            'SampleRate':str(self.sample_rate),\n",
    "            'Text':self.text,\n",
    "            'TextType':self.text_type,\n",
    "            'VoiceId':self.voice_id\n",
    "        }\n",
    "        try:\n",
    "            response = polly_client.synthesize_speech(**args)\n",
    "            if 'AudioStream' in response:\n",
    "                with wave.open(raw_pcm_bin, 'wb') as wav_file:\n",
    "                    wav_file.setparams((1, 2, self.sample_rate, 0, 'NONE', 'NONE'))\n",
    "                    wav_file.writeframes(response['AudioStream'].read())\n",
    "            raw_pcm_bin.seek(0)\n",
    "        except Exception as e:\n",
    "            print('synthesize_speech exception: ', e)\n",
    "        \n",
    "        return raw_pcm_bin\n",
    "    \n",
    "    def pitch_shift(self):\n",
    "        amplitude, _ = sf.read(self.raw_pcm_bin)\n",
    "        width = amplitude.shape[0]//self.sep_num\n",
    "        segment_freq_list = []\n",
    "        for i in range(self.sep_num):\n",
    "            if i==self.sep_num-1:\n",
    "                sampling_amp = amplitude[i*width:-1]\n",
    "            else:\n",
    "                sampling_amp = amplitude[i*width:(i+1)*width]\n",
    "            fft_data = np.fft.fft(sampling_amp)\n",
    "            freq_list = np.fft.fftfreq(sampling_amp.shape[0], d=1.0/self.sample_rate)\n",
    "            amp = np.abs(fft_data)\n",
    "            amp_p = amp[0: amp.shape[0]//2]\n",
    "            freq_list_p = freq_list[0: freq_list.shape[0]//2]\n",
    "            segment_freq_list.append(freq_list_p[amp_p.argmax()])\n",
    "        shift_amplitude_list = []\n",
    "        data_points = 0\n",
    "        for i, origin_freq in enumerate(segment_freq_list):\n",
    "            n_steps = np.log2(self.scale_freq/origin_freq) * 12\n",
    "            if i == self.sep_num-1:\n",
    "                shift_amplitude_list.append(pyrb.pitch_shift(amplitude[i*width:-1], sr = self.sample_rate, n_steps=n_steps))\n",
    "            else:\n",
    "                shift_amplitude_list.append(pyrb.pitch_shift(amplitude[i*width:(i+1)*width], sr = self.sample_rate, n_steps=n_steps))\n",
    "            data_points += shift_amplitude_list[-1].shape[0]\n",
    "        shift_amplitude = np.zeros((data_points),dtype=np.float64)\n",
    "        start_index = 0\n",
    "        for i in range(self.sep_num):\n",
    "            shift_amplitude[start_index:start_index + shift_amplitude_list[i].shape[0]] = shift_amplitude_list[i]\n",
    "            start_index += shift_amplitude_list[i].shape[0]\n",
    "        return shift_amplitude\n",
    "    def time_stretch(self):\n",
    "        origin_time = self.shift_pcm_array.shape[0] / self.sample_rate\n",
    "        ratio = origin_time / self.length_sec\n",
    "        return pyrb.time_stretch(self.shift_pcm_array, self.sample_rate, ratio)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [\n",
    "    {'text':'かー','length_sec':0.5,'scale':'C'},\n",
    "    {'text':'えー','length_sec':0.5,'scale':'D'},\n",
    "    {'text':'るー','length_sec':0.5,'scale':'E'},\n",
    "    {'text':'のー','length_sec':0.5,'scale':'F'},\n",
    "    {'text':'うー','length_sec':0.5,'scale':'E'},\n",
    "    {'text':'たー','length_sec':0.5,'scale':'D'},\n",
    "    {'text':'がー','length_sec':0.5,'scale':'C'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flog_np_arrays = [SingingVoiceGenerator(**s).time_stretch_array for s in score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = 0\n",
    "for flog_np_array in flog_np_arrays:\n",
    "    data_points += flog_np_array.shape[0]\n",
    "concat_np_array = np.zeros((data_points),dtype=np.float64)\n",
    "start_index = 0\n",
    "for flog_np_array in flog_np_arrays:\n",
    "    concat_np_array[start_index:start_index+flog_np_array.shape[0]] = flog_np_array\n",
    "    start_index += flog_np_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_wav_path = os.path.join('./work', 'concat.wav')\n",
    "sf.write(shift_wav_path, concat_np_array, 16000, subtype=\"PCM_16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
